
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
<!-- If no var is set for $page_title on the top of each page than default title will be HDF Group -->

<title>
Filters</title>
	<meta name="keywords" content="hdf, hdfeos, blog, hdf blog, hdf5 blog, hdf5, hdf4, hdf tools, hdf libraries, hdf viewer, hdf format, hdf file, hdf java, nafxcw.lib, phdf5, open source, hierarchical data format, ncsa, database, python hdf, mike folk, hdfview, hdf5 parallel" />
	<meta name="description" content="The HDF Group is a not-for-profit corporation with the mission of sustaining the HDF technologies and supporting HDF user communities worldwide with production-quality software and services." />
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="expires" content="Wed, 26 Feb 2010 08:21:57 GMT" />
	<meta name="verify-v1" content="/m03HNmaDgGAcDe0PFtEVnXGtCkoeOocjr/Jwey2gdI=" />
	<link href="/css/layout.css" rel="stylesheet" type="text/css" media="screen, projection" />
	<link href="/css/print.css" rel="stylesheet" type="text/css" media="print" />
	<link rel="stylesheet" type="text/css" href="/css/js_style.css" />
	<link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon" />
	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/prototype/1.7.2.0/prototype.js"></script>
	<!--<script type="text/javascript" src="/scriptaculous/lib/prototype.js"></script>-->
	<script type="text/javascript" src="/scriptaculous/src/effects.js"></script>
	<script type="text/javascript" src="/scriptaculous/validation.js"></script>
	<script type="text/javascript" src="/scriptaculous/animatedcollapse.js"></script>
	<script type="text/javascript" src="/scriptaculous/rollover.js"></script>	
	<script type="text/javascript" src="/scriptaculous/functions.js"></script>
	<script type="text/javascript" src="/scriptaculous/sorttable.js"></script>
	<!--<script type="text/javascript" src="/jquery-1.2.2.pack.js"></script>-->
	<script type="text/javascript" src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
	<script type="text/javascript" src="/scriptaculous/jssor.slider.min.js"></script>

 	<link rel="stylesheet" type="text/css" href="/featuredcontentglider.css" />
    <script type="text/javascript" src="/featuredcontentglider.js"></script>

	</head>
	<body>
	<div id="mast_head">
		<a href="https://www.hdfgroup.org/"><img src="/images/hdf_logo.jpg" height="70" style="display:block; padding-left:10px;" align="left" alt="hdf images" /></a>
		<img src="/images/logo_5.jpg" height="70" style="display:block;" align="right" alt="hdf images" />
	</div> 
				
	<div id="nav_wrapper">
		<div>
		<div id="section-services">
			<ul id="nav">
				<li id="t-index"><a href="https://www.hdfgroup.org/">Home</a> </li>
				<li id="t-products"><a href="/products/">Products</a></li>
				<li id="t-services"><a href="/services/">Services</a></li>
				<li id="t-about"><a href="/about/">About Us</a></li>
				<li id="t-news"><a href="/news/">News</a> </li>
				<li id="t-blog"><a href="https://www.hdfgroup.org/blog">Blog</a></li>
				<li id="t-contact"><a href="/about/contact.html">Contact Us</a></li> 
			</ul>
			<script type="text/javascript">
			
  (function() {
    var cx = '007250492606109219119:sb2eg2bgoyy';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>	
					<script type="text/javascript">
					    jQuery(document).ready(function ($) {
					        // var options = {
					        //     $ArrowNavigatorOptions: {
					        //         $Class: $JssorArrowNavigator$,
					        //         $ChanceToShow: 2
					        //     }
					        // };					    	


							var options = { 
											$AutoPlay: true, $SlideshowOptions: { $Class: $JssorSlideshowRunner$, $Transitions: [{ $Duration:5000, $Fade: true, $Opacity:2 }] } , 
											$ArrowNavigatorOptions: { 
												$Class: $JssorArrowNavigator$, 
												$ChanceToShow: 2
											}
										  };


					        var jssor_slider1 = new $JssorSlider$('slider1_container', options);
					    });
					</script>
									                  
			
		</div>
		</div>             
	</div>
				
<!--START: MAIN -->
<div id="wrapper" style="margin-top:-15px;"> 

<!--START: SIDE_BAR -->
<div id="side_bar">

<form method="get" action="" class="form" >
	<select onchange="window.open(this.options[this.selectedIndex].value,'_top')" name="" style="border:2px solid #c1c1c1;">
		<option value="" class="ql1">- - Quick Links - -</option>
		<option value="/HDF5/" class="ql">HDF5</option>
		<option value="/products/hdf4/" class="ql">HDF4</option>
		<option value="/tools/" class="ql">Tools</option>
		<option value="/projects/" class="ql">Projects</option>
		<option value="/downloads/" class="ql">Downloads</option>
		<option value="/documentation/" class="ql">Documentation</option>
	        <option value="/pubs/" class="ql">Publications</option>
		<option value="/about/" class="ql">Contact Us</option>
	</select>
</form>
<ul style="border:1px solid #c1c1c1; margin-top:25px;"> 

	<li style="background:url(/images/menubg.png); padding:0px; padding-left:7px; color:#27343C; font-weight:500; text-align:left;">
	LINKS</li><li><a href="https://www.hdfgroup.org/">Main Website</a></li><li><a href="/HDF5/">HDF5</a></li><li><a href="/products/hdf4/">HDF4</a></li><li><a href="/tools/">Tools</a></li><li><a href="/projects/">Projects</a></li><li><a href="/downloads/">Downloads</a></li><li><a href="/documentation/">Documentation</a></li><li><a  href="/pubs/">Publications</a></li></ul> 

</div>

<!--END: SIDE_BAR -->

<!--START: CONTENT -->
<div id="content">
<p><font color="red"><center><strong>This web site is no longer maintained (but will remain online).<br /> Please see The HDF Group's new <a href="https://portal.hdfgroup.org">Support Portal</a> for the latest information.</strong></center></font></p>
	<div class=bc><p style="color:orange; ";><a href="/" title="HOME">HOME</a> &gt; <a href="/services/" title="SERVICES">SERVICES</a></p></div><fieldset><h1>Filters</h1></fieldset>
			 


<a name="lzo"> </a>
<h3>LZO Filter</h3>
<p>
<strong>Filter ID:</strong> 305
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
<ul class="ul">
<li class="li3">
    LZO is a portable lossless data compression library written in ANSI C.
</li>

<li class="li3">
    Reliable and thoroughly tested. High adoption - each second terrabytes 
    of data are compressed by LZO. No bugs since the first release back in 1996.
</li>

<li class="li3">
    Offers pretty fast compression and *extremely* fast decompression.
</li>

<li class="li3">
    Includes slower compression levels achieving a quite competitive 
    compression ratio while still decompressing at this very high speed.
</li>

<li class="li3">
    Distributed under the terms of the GNU General Public License (GPL v2+). 
    Commercial licenses are available on request.
</li>

<li class="li3">
    Military-grade stability and robustness.
</li>
</ul>

<p>
<strong>Links:</strong>
</p>

<p>
<a href="http://www.oberhumer.com/opensource/lzo/">http://www.oberhumer.com/opensource/lzo/</a><br />
<a href="http://www.pytables.org">http://www.pytables.org</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Francesc Alted<br />
Email: faltet at pytables dot org 
</p>

<hr />

<a name="bzip2"> </a>
<h3>BZIP2 Filter</h3>
<p>
<strong>Filter ID:</strong> 307
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
bzip2 is a freely available, patent free, high-quality data compressor. It 
typically compresses files to within 10% to 15% of the best available 
techniques (the PPM family of statistical compressors), whilst being around 
twice as fast at compression and six times faster at decompression.
</p>

<p>
<strong>Links:</strong>
</p>

<p>
<a href="http://www.bzip.org">http://www.bzip.org</a><br />
<a href="http://www.pytables.org">http://www.pytables.org</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Francesc Alted<br />
Email: faltet at pytables dot org 
</p>

<hr />

<a name="lzf"> </a>
<h3>LZF Filter</h3>

<p>
<strong>Filter ID:</strong> 32000
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
The LZF filter is an alternative DEFLATE-style compressor for HDF5 datasets, 
using the free LZF library by Marc Alexander Lehmann.  Its main benefit over 
the built-in HDF5 DEFLATE filter is speed; in memory-to-memory operation as 
part of the filter pipeline, it typically compresses 3x-5x faster than DEFLATE,
and decompresses 2x faster, while maintaining 50% to 90% of the DEFLATE 
compression ratio.
</p>

<p>
LZF can be used to compress any data type, and requires no compile-time or 
run-time configuration.  HDF5 versions 1.6.5 through 1.8.3 are supported.  
The filter is written in C and can be included directly in C or C++ 
applications; it has no external dependencies.  The license is 3-clause BSD 
(virtually unrestricted, including commercial applications).
</p>

<p>
More information, downloads, and benchmarks, are available at the 
<a href="http://h5py.org/lzf/">http://h5py.org/lzf/</a>.
</p>

<p>
<strong>Additional Information:</strong>
</p>

<p>
The LZF filter was developed as part of the h5py project, which implements 
a general-purpose interface to HDF5 from Python.
</p>

<p>
<strong>Links:</strong>
</p>

<p>
The h5py homepage:  <a href="http://h5py.org">http://h5py.org</a><br />
The LZF library homepage:  
<a href="http://home.schmorp.de/marc/liblzf.html">http://home.schmorp.de/marc/liblzf.html</a>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Andrew Collette<br />
Web: <a href="http://h5py.org">http://h5py.org</a>
</p>

<hr />
<a name="blosc"> </a>
<p>

<h3>Blosc Filter</h3>
<p>
<strong>Filter ID:</strong> 32001
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
Blosc is a high performance compressor optimized for binary data. It
has been designed to compress data very fast, at the expense of
achieving lesser compression ratios than, say, zlib+shuffle.  It is
mainly meant to not introduce a significant delay when dealing with
data that is stored in high-performance I/O systems (like large RAID
cabinets, or even the OS filesystem memory cache).
</p>

<p>
It uses advanced cache-efficient techniques to reduce activity on the
memory bus as much as possible. It also leverages SIMD (SSE2) and
multi-threading capabilities present in nowadays multi-core processors
so as to accelerate the compression/decompression process to a
maximum.
</p>

<p>
<strong>Links:</strong>
</p>

<p>
<a href="http://blosc.org/">http://blosc.org/</a><br />
<a href="http://www.pytables.org">http://www.pytables.org</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Francesc Alted<br />
Email: faltet at pytables dot org 
</p>

<hr />

<a name="mafisc"> </a>
<h3>MAFISC Filter</h3>

<p>
<strong>Filter ID:</strong> 32002
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
This compressing filter exploits the multidimensionality and
smoothness characterizing many scientific data sets. It
adaptively applies some filters to preprocess the data and uses
lzma as the actual compression step. It significantly
outperforms pure lzma compression on most datasets.
</p>

<p>
The software is currently under a rather unrestrictive two clause BSD
style license.
</p>

<p>
<strong>Links:</strong>
</p>

<p>
<a href="http://wr.informatik.uni-hamburg.de/research/projects/icomex/mafisc">http://wr.informatik.uni-hamburg.de/research/projects/icomex/mafisc</a>
</p>

<!--
<p>
A patch for HDF5 version 1.8.7, introducing this algorithm into the
h5repack utility can be found here:
<a href="http://files.wr.informatik.uni-hamburg.de/hdf5-dkrz-compressor.patch">http://files.wr.informatik.uni-hamburg.de/hdf5-dkrz-compressor.patch</a>
</p>
-->


<p>
<strong>Contact Information:</strong>
</p>
<p>
Nathanael Huebbe <br />
Email: nathanael.huebbe @ informatik dot uni-hamburg dot de <br />
</p>

<hr />

<a name="snappy"> </a>
<h3>Snappy Filter</h3>

<p>
<strong>Filter ID:</strong> 32003
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
Snappy is a compression/decompression library. It does not aim for maximum compression, or compatibility with any other compression library; instead, it aims for very high speeds and reasonable compression. For instance, compared to the fastest mode of zlib, Snappy is an order of magnitude faster for most inputs, but the resulting compressed files are anywhere from 20% to 100% bigger. On a single core of a Core i7 processor in 64-bit mode, Snappy compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more.
</p>

<p>
Snappy is widely used inside Google, in everything from BigTable and MapReduce to our internal RPC systems. (Snappy has previously been referred to as .Zippy. in some presentations and the likes.) 
</p>

<p>
<strong>Links:</strong>
</p>

<p>
<!--
<a href="http://code.google.com/p/snappy/">http://code.google.com/p/snappy/</a>
-->
<a href="http://google.github.io/snappy/">http://google.github.io/snappy/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Michael Rissi (Dectris Ltd.)<br />
Email: michael dot rissi at dectris dot com
</p>

<hr />

<a name="lz4"> </a>
<h3>LZ4 Filter</h3>

<p>
<strong>Filter ID:</strong> 32004
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
LZ4 is a very fast lossless compression algorithm, providing
compression speed at 300 MB/s per core, scalable with multi-cores CPU.
It also features an extremely fast decoder, with speeds up and beyond
1GB/s per core, typically reaching RAM speed limits on multi-core
systems. For a format description of the LZ4 compression filter in HDF5,
see <a href="./filters/HDF5_LZ4.pdf">HDF5_LZ4.pdf</a>.
</p>

<p>
<strong>Links:</strong>
</p>

<p>
LZ4 Algorithm: &nbsp; <a href="https://github.com/nexusformat/HDF5-External-Filter-Plugins/tree/master/LZ4">https://github.com/nexusformat/HDF5-External-Filter-Plugins/tree/master/LZ4</a>
</p>
<p>
LZ4 Code: 
<ul class="ul">
Although the LZ4 software is not supported by The HDF Group, it is
included in The HDF Group SVN repository so that it can be tested
regularly with HDF5. For convenience, users can obtain it from SVN
with the following command:
<pre>
   svn checkout https://svn.hdfgroup.org/hdf5_plugins/trunk/LZ4 LZ4
</pre>
</ul>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Michael Rissi (Dectris Ltd.)<br />
Email: michael dot rissi at dectris dot com
</p>

<hr />

<a name="apax"></a>
<h3>APAX</h3>

<p>
<strong>Filter ID:</strong> 32005
</p>

<p>Appears to be no longer available</p>

<!--
<p>
<strong>Filter Description:</strong>
</p>

<p>
Samplify's APAX numerical encoding technology provides user-controlled encoding of any type of
numerical data set, including integers, floats, and doubles. SIMD-optimized for execution on 
Intel x86/x64, APAX achieves an encoding throughput of 200 Mbytes/sec  on a single core, 
achieving up to 3.2 GBytes/sec on a single compute node.
</p>

<p>
The APAX Profiler web-based analysis tool provides the developer with a recommendation of the 
maximum encoding rate for his/her data set without changing analytical results. The Profiler 
saves the encoding parameters for later use by the APAX filter within HDF5, enabling each data 
set in the HDF5 file to be stored with optimized size.
</p>

<p>
<strong>Links:</strong>
</p>

<p>
<a href="http://www.samplify.com/products/apax-sw/sdk-for-x64/">http://www.samplify.com/products/apax-sw/sdk-for-x64/</a><br />
<a href="http://profiler.samplify.com/">http://profiler.samplify.com/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Email: <a href="mailto:sales@samplify.com">sales at samplify dot com</a>
</p>

-->
<hr />

<a name="cbf"></a>
<h3>CBF</h3>

<p>
<strong>Filter ID:</strong> 32006
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
All imgCIF/CBF compressions and decompressions, including Canonical, Packed, 
Packed Vesrsion 2, Byte Offset and Nibble Offset. <br />
License Information:  GPL and LGPL
</p>

<!--
<p>
<strong>Links:</strong>
</p>
-->

<p>
<strong>Contact Information:</strong>
</p>

<p>
Herbert J. Bernstein<br />
Email: yayahjb  at  gmail dot com
</p>

<hr />

<a name="jpegxr"></a>
<h3>JPEG-XR</h3>

<p>
<strong>Filter Id:</strong> 32007
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
Filter that allows HDF5 image datasets to be compressed or decompressed
using the JPEG-XR compression method.
</p>


<p>
<strong>Links:</strong>
</p>
<p>
<a href="https://jxrlib.codeplex.com">JPEG-XR Compression Method</a><br />
<a href="https://hdf5jpegxr.codeplex.com">JPEG-XR Filter for HDF5</a>

</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Marvin Albert <br />
Email: marvin dot albert at gmail dot com
</p>

<hr />

<a name="bitshuffle"></a>
<h3>bitshuffle</h3>

<p>
<strong>Filter Id:</strong> 32008
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
This filter shuffles data at the bit level to improve compression. CHIME uses this filter for data
acquisition.
</p>

<p>
<strong>Links:</strong>
</p>
<p>
<a href="https://github.com/kiyo-masui/bitshuffle">bitshuffle</a><br />
<a href="http://chime.phas.ubc.ca">CHIME</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Kiyoshi Masui<br />
Email: kiyo at physics dot ubc dot ca
</p>

<hr />
<a name="spdp"></a>
<h3>SPDP</h3>

<p>
<strong>Filter Id:</strong> 32009
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
SPDP is a fast, lossless, unified compression/decompression algorithm
designed for both 32-bit single-precision (float) and 64-bit
double-precision (double) floating-point data.  It also works on other data.
</p>

<p>
<strong>Link to the filter:</strong></p>
<p>
<a href="http://cs.txstate.edu/~burtscher/research/SPDP/">http://cs.txstate.edu/~burtscher/research/SPDP/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Martin Burtscher<br />
Email: burtscher at txstate dot edu
</p>

<hr />
<a name="lpcrice"></a>
<h3>LPC-Rice</h3>

<p>
<strong>Filter Id:</strong> 32010
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
LPC-Rice is a fast lossless compression codec that employs Linear Predictive Coding together with Rice coding. It
supports multi-threading and SSE2 vector instructions, enabling it to exceed compression and decompression speeds of 1 GB/s.
</p>

<p>
<strong>Link to the filter:</strong></p>
<p>

<p>
<a href="https://sourceforge.net/projects/lpcrice/">https://sourceforge.net/projects/lpcrice/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Frans van den Bergh<br />
Email: fvdbergh at  csir dot  co  dot za
</p>

<p>
Derick Swanepoel<br />
Email: dswanepoel  at gmail dot  com
</p>

<hr />

<a name="ccsds123"></a>
<h3>CCSDS-123</h3>

<p>
<strong>Filter Id:</strong> 32011
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
CCSDS-123 is a multi-threaded HDF5 compression filter using the ESA CCSDS-123 implementation.
</p>

<p>
<strong>Link to the filter:</strong></p>
<p>

<p>
<a href="https://sourceforge.net/projects/ccsds123-hdf-filter/">https://sourceforge.net/projects/ccsds123-hdf-filter/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Frans van den Bergh<br />
Email: fvdbergh at  csir dot  co  dot za
</p>

<p>
Derick Swanepoel<br />
Email: dswanepoel  at gmail  dot   com
</p>

<hr />

<a name="jpegls"></a>
<h3>JPEG-LS</h3>

<p>
<strong>Filter Id:</strong> 32012
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
JPEG-LS is a multi-threaded HDF5 compression filter using the CharLS JPEG-LS implementation.
</p>

<p>
<strong>Link to the filter:</strong></p>
<p>

<p>
<a href="https://sourceforge.net/projects/jpegls-hdf-filter/">https://sourceforge.net/projects/jpegls-hdf-filter/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Frans van den Bergh<br />
Email: fvdbergh at  csir dot  co  dot za
</p>

<p>
Derick Swanepoel<br />
Email: dswanepoel  at  gmail dot com  
</p>

<hr />
<!------------------------------------------------>


<a name="zfp"></a>
<h3>zfp</h3>

<p>
<strong>Filter Id:</strong> 32013
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
zfp is a BSD licensed open source C++ library for compressed floating-point arrays that support very high throughput 
read and write random access. zfp was designed to achieve high compression ratios and therefore uses 
<strong>lossy</strong> but optionally error-bounded compression. Although bit-for-bit lossless compression is not 
always possible, zfp is usually accurate to within machine epsilon in near-lossless mode, and is 
often orders of magnitude more accurate and faster than other lossy compressors.


</p>

<p>
<strong>Link to the filter:</strong></p>
<p>
<a href="https://github.com/LLNL/H5Z-ZFP">https://github.com/LLNL/H5Z-ZFP</a>
</p>

<p>
For more information see:
   <a href="http://computation.llnl.gov/projects/floating-point-compression/">http://computation.llnl.gov/projects/floating-point-compression/</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Mark Miller<br />
Email: miller86  at llnl dot gov
</p>
<p>
Peter Lindstrom<br />
Email: pl at   llnl dot  gov
</p>

<p>
</p>

<hr />

<!------------------------------------------------>
<a name="fpzip"></a>
<h3>fpzip</h3>

<p>
<strong>Filter Id:</strong> 32014
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
fpzip is a library for lossless or lossy compression of 2D or 3D floating-point scalar fields. Although written in C++, fpzip has a C interface.  fpzip was developed by Peter Lindstrom at LLNL.
</p>

<p>
<strong>Link to the filter:</strong></p>
<p>

</p>

<p>
For more information see:
   <a href="http://computation.llnl.gov/projects/floating-point-compression/">http://computation.llnl.gov/projects/floating-point-compression/</a>
</p>


<p>
<strong>Contact Information:</strong>
</p>

<p>
Peter Lindstrom<br />
Email: pl at   llnl dot  gov
</p>

<p>
</p>


<!------------------------------------------------>
<hr />
<a name="zstandard"></a>
<h3>Zstandard</h3>
<p>
<strong>Filter Id:</strong> 32015
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
Zstandard is a real-time compression algorithm, providing high compression
ratios. It offers a very wide range of compression / speed trade-offs,
while being backed by a very fast decoder. The <a href="http://www.zstd.net/">Zstandard library</a> is provided
as open source software using a BSD license.


<p>
<strong>Link to the filter:</strong></p>
</p>
<p>
<a href="https://github.com/aparamon/HDF5Plugin-Zstandard">https://github.com/aparamon/HDF5Plugin-Zstandard</a>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Andrey Paramonov<br />
Email: paramon  at acdlabs dot  ru
</p>

<!------------------------------------------------>
<hr />
<a name="b3d"></a>
<h3>B³D</h3>
<p>
<strong>Filter Id:</strong> 32016
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
B³D is a fast (~1 GB/s), GPU based image compression method, developed
for light-microscopy applications. Alongside lossless compression, it
offers a noise dependent lossy compression mode, where the loss can be
tuned as a proportion of the inherent image noise (accounting for photon
shot noise and camera read noise). It not only allows for fast
compression during image, but can achieve compression ratios up 100.
</p>
<p>
<strong>Information:</strong>
<p>
<a href="http://www.biorxiv.org/content/early/2017/07/21/164624">http://www.biorxiv.org/content/early/2017/07/21/164624</a>
</p>


<!------------------------------------------------>
<hr />
<a name="SZ"></a>
<h3>SZ</h3>

<p>
<strong>Filter Id:</strong> 32017
</p>

<p>
<strong>Filter Description:</strong>
</p>
<p>
SZ is a fast and efficient error-bounded lossy compressor for floating-point data. It was developed for scientific applications
producing large-scale HPC data sets. SZ supports C, Fortran, and Java and has been tested on Linux and Mac OS X.
</p>

<p>
<strong>Link to the filter:</strong>
</p>
<p>
<a href="https://collab.cels.anl.gov/display/ESR/SZ">Information</a>
<br />
<a href="https://github.com/disheng222/SZ">github</a>
<br />
<a href="http://www.mcs.anl.gov/~shdi/download/sz-download.html">License</a>
</p>

<p>
<strong>Contact Information:</strong>
</p>

<p>
Sheng Di<br />
Email: sdi1 at   anl dot gov 
</p>
<p>
Franck Cappello <br />
Email: cappello  at  mcs   dot   anl dot gov
</p>

<!------------------------------------------------>
<hr />
<a name="fcidecomp"></a>
<h3>FCIDECOMP</h3>

<p>
<strong>Filter Id:</strong> 32018
</p>

<p>
<strong>Filter Description:</strong>
</p>

<p>
FCIDECOMP is a third-party compression filter used at EUMETSAT for the compression of netCDF-4 files.
It is a codec implementing JPEG-LS using CharLS used for satellite imagery.
</p>

<p>
<strong>Link to the filter:</strong></p>
<p>
All software and documentation can be found at this link:
<a href="ftp://ftp.eumetsat.int/pub/OPS/out/test-data/Test-data-for-External-Users/MTG_FCI_L1c_Compressed-Datasets_and_Decompression-Plugin_April2017/Decompression_Plugin/">ftp://ftp.eumetsat.int/pub/OPS/out/test-data/Test-data-for-External-Users/MTG_FCI_L1c_Compressed-Datasets_and_Decompression-Plugin_April2017/Decompression_Plugin/</a>
</p>


<p>
<strong>Contact Information:</strong>
</p>

<p>
Dr. Daniel Lee<br />
Email: daniel dot  lee  at eumetsat dot int
</p>

<p>
</p>

<!------------------------------------------------>
<hr />
<i>
- - Last modified: 01 September 2017</i>
	   </div>
	   <!--END: CONTENT -->
<!--END: WRAPPER -->
<script src="/scriptaculous/gatag.js" type="text/javascript"></script>

<!-- <script type="text/javascript" src="//code.jquery.com/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="//code.jquery.com/jquery-migrate-1.2.1.min.js"></script> -->
				
<!--
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>

<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-3782034-1");
pageTracker._trackPageview();
} catch(err) {}</script>
-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3782034-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>
 
